{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ecc3d7ca",
   "metadata": {},
   "source": [
    "## HTML MAKER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f74f737",
   "metadata": {},
   "outputs": [],
   "source": [
    "## STEP 0: Initialization.\n",
    "import json\n",
    "import re\n",
    "import fnmatch\n",
    "import os\n",
    "import os.path\n",
    "\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "from tkinter import ttk\n",
    "\n",
    "class App(tk.Frame):\n",
    "    def __init__(self, master): # Runs as soon as program starts\n",
    "            super().__init__(master)\n",
    "            \n",
    "            frm = ttk.Frame(root, padding='0.1i')\n",
    "            frm.grid()\n",
    "            frm.rowconfigure(1, weight=3, minsize='0.5i')\n",
    "            frm.rowconfigure(2, weight=3, minsize='0.5i')\n",
    "            frm.columnconfigure(0, weight=3, minsize='0.5i')\n",
    "            \n",
    "            ttk.Button(\n",
    "                frm, text=\"Where are your JSON files?\", command=self.choose_json_directory).grid(column=0, row=0, columnspan=1, sticky=\"NW\")\n",
    "            self.jsonpath_display_text = tk.StringVar()\n",
    "            self.jsonpath_display_text.set(\"Selected JSON Directory: \")\n",
    "            self.jsonpath = \"\"\n",
    "            self.json_directory_label = ttk.Label(frm, text=\"Selected JSON Directory: \", width=80)\n",
    "            self.json_directory_label.grid(column=0, row=1, columnspan=3)\n",
    "            self.json_directory_label['textvariable'] = self.jsonpath_display_text\n",
    "\n",
    "            ttk.Button(\n",
    "                frm, text=\"Where do you want your HTML files?\", command=self.choose_html_directory).grid(column=1, row=0, columnspan=1)\n",
    "            self.htmlpath_display_text = tk.StringVar()\n",
    "            self.htmlpath_display_text.set(\"Selected HTML Directory: \")\n",
    "            self.htmlpath = \"\"\n",
    "            self.html_directory_label = ttk.Label(frm, text=\"Selected HTML Directory: \", width=80)\n",
    "            self.html_directory_label.grid(column=0, row=2, columnspan=3)\n",
    "            self.html_directory_label['textvariable'] = self.htmlpath_display_text\n",
    "            \n",
    "            self.target_post_type_display_text = tk.StringVar()\n",
    "            self.target_post_type_display_text.set(\"Target Post Type: \")\n",
    "            self.target_post_type_label = ttk.Label(frm,text=\"Target Post Type: \",width=80)\n",
    "            self.target_post_type_label.grid(column=0, row=3, columnspan=3)\n",
    "            self.target_post_type_label['textvariable'] = self.target_post_type_display_text\n",
    "\n",
    "            options_list = [\"\", \"regular\", \"answer\", \"text\", \"photo\", \"audio\", \"video\", \"link\", \"conversation\", \"quote\"]\n",
    "            self.target_post_type_input = tk.StringVar(frm)\n",
    "            self.target_post_type = ttk.OptionMenu(frm, self.target_post_type_input, *options_list)\n",
    "            self.target_post_type.grid(column=1, row=3, columnspan=3)\n",
    "            self.target_post_type_input.set(\"Select an Option\")\n",
    "\n",
    "            self.tag_search_display_text = tk.StringVar()\n",
    "            self.tag_search_display_text.set(\"Tag Search Term: \")\n",
    "            self.tag_search_label = ttk.Label(frm,text=\"Tag Search Term: \",width=80)\n",
    "            self.tag_search_label.grid(column=0, row=4, columnspan=3)\n",
    "            self.tag_search_label['textvariable'] = self.tag_search_display_text\n",
    "\n",
    "            self.tag_search_input = tk.StringVar()\n",
    "            self.tag_search = ttk.Entry(frm, textvariable=self.tag_search_input)\n",
    "            self.tag_search.grid(column=1, row=4, columnspan=3)\n",
    "            self.tag_search['textvariable'] = self.tag_search_input\n",
    "\n",
    "            self.search_display_text = tk.StringVar()\n",
    "            self.search_display_text.set(\"Search Term: \")\n",
    "            self.search_label = ttk.Label(frm,text=\"Search Term: \",width=80)\n",
    "            self.search_label.grid(column=0, row=5, columnspan=3)\n",
    "            self.search_label['textvariable'] = self.search_display_text\n",
    "\n",
    "            self.search_input = tk.StringVar()\n",
    "            self.search = ttk.Entry(frm, textvariable=self.search_input)\n",
    "            self.search.grid(column=1, row=5, columnspan=3)\n",
    "            self.search['textvariable'] = self.search_input\n",
    "\n",
    "            self.status_display_text = tk.StringVar()\n",
    "            self.status_label = ttk.Label(frm, text=\"\", width=80)\n",
    "            self.status_label.grid(column=0, row=6, columnspan=3)\n",
    "            self.status_label['textvariable'] = self.status_display_text\n",
    "            \n",
    "            self.confirm_button = ttk.Button(frm, text=\"Confirm\", command=self.execute) # Self passes itself as first param\n",
    "            self.confirm_button.grid(column=1, row=7, columnspan=1, sticky=\"SE\")\n",
    "            self.confirm_button.state(['disabled'])\n",
    "            self.exit_button = ttk.Button(frm, text=\"Exit\", command=root.destroy)\n",
    "            self.exit_button.grid(column=2, row=7, columnspan=1, sticky=\"SE\")\n",
    "\n",
    "    def choose_json_directory(self):\n",
    "        jsonpath = filedialog.askdirectory(title=\"Where are your JSON files?\")\n",
    "        self.jsonpath = jsonpath\n",
    "        self.jsonpath_display_text.set(f\"JSONs are in: {jsonpath}\") # Sets text of label to htmlpath)\n",
    "        if os.path.exists(jsonpath): # If path exists, enable button\n",
    "            self.confirm_button.state(['!disabled'])\n",
    "\n",
    "    def choose_html_directory(self):\n",
    "        htmlpath = filedialog.askdirectory(title=\"Where do you want your HTML files?\")\n",
    "        self.htmlpath = htmlpath\n",
    "        self.htmlpath_display_text.set(f\"HTMLs will go to: {htmlpath}\") # Sets text of label to htmlpath)\n",
    "        if os.path.exists(htmlpath): # If path exists, enable button\n",
    "            self.confirm_button.state(['!disabled'])\n",
    "\n",
    "    def execute(self):\n",
    "        index = 0\n",
    "        dup_index = 0\n",
    "        parsed_ids = []\n",
    "\n",
    "        jsonpath = self.jsonpath\n",
    "        htmlpath = self.htmlpath \n",
    "        target_post_type = self.target_post_type_input.get() \n",
    "        tag_search = self.tag_search_input.get() \n",
    "        search_term = self.search_input.get() \n",
    "\n",
    "        ## STEP 2.0: Search jsonpath for .json files.\n",
    "        for path, dirs, files in os.walk(jsonpath):\n",
    "                print(f\"{path}\")\n",
    "                for name in files:\n",
    "                    if name.endswith((\".json\")):\n",
    "                        f = open(str(path + \"\\\\\" + name), encoding=\"utf-8-sig\")\n",
    "                        data = json.load(f)\n",
    "\n",
    "                        def categorizer(data):\n",
    "                            ## STEP 2.4: Categorize the post.\n",
    "                            if 'type' not in data.keys():\n",
    "                                post_type = 'regular'\n",
    "                            elif 'originalType' in data.keys():\n",
    "                                post_type = data['originalType']\n",
    "                            else:\n",
    "                                post_type = data['type']\n",
    "                            \n",
    "                            return post_type\n",
    "                        \n",
    "                        post_type = categorizer(data)\n",
    "\n",
    "                        if post_type == target_post_type:\n",
    "\n",
    "                            def tag_reader(data):\n",
    "                                if \"tags\" in data.keys():\n",
    "                                    Tags = \", \\r\\n\".join(data[\"tags\"]) + f\", {post_type}\"\n",
    "                                else:\n",
    "                                    Tags = f\"Untagged, {post_type}\"\n",
    "                                return Tags\n",
    "                            \n",
    "                            Tags = tag_reader(data)\n",
    "\n",
    "                            if tag_search in Tags:\n",
    "\n",
    "                                idnum = data['id']\n",
    "\n",
    "                                def op_finder(data):\n",
    "                                    if 'reblogged_root_name' in data.keys() and data['reblogged_root_name'] != '':\n",
    "                                        op = data['reblogged_root_name']\n",
    "                                    elif 'reblogged-root-name' in data.keys() and data['reblogged-root-name'] != '':\n",
    "                                        op = data['reblogged-root-name']\n",
    "                                    elif 'blog' in data.keys():\n",
    "                                        op = data['blog']['name']\n",
    "                                    else:\n",
    "                                        op = data['tumblelog']['name']\n",
    "\n",
    "                                    if 'blog' in data.keys():\n",
    "                                        from_blog = data['blog']['name']\n",
    "                                    else:\n",
    "                                        from_blog = data['tumblelog']['name']\n",
    "\n",
    "                                    return op, from_blog\n",
    "                                \n",
    "                                op, from_blog = op_finder(data)\n",
    "\n",
    "                                def json_structureizer(data):\n",
    "                                    ## STEP 2.7: Categorize the .json file structure.\n",
    "                                    if 'trail' in data.keys():\n",
    "                                        disp = 'CANNOT CURRENTLY DISPLAY'\n",
    "                                        JSON_type = \"SVC\"\n",
    "                                        date = data['date']\n",
    "                                    elif \"date-gmt\" in data.keys():\n",
    "                                        JSON_type = \"API\"\n",
    "                                        date = data['date-gmt']\n",
    "                                        if 'regular-body' in data.keys():\n",
    "                                            disp = data['regular-body']\n",
    "                                        elif 'post-text' in data.keys():\n",
    "                                            disp = data['post-text']\n",
    "                                    elif 'regular-title' in data.keys():\n",
    "                                        JSON_type = \"SVC\"\n",
    "                                        date = data['date']\n",
    "                                        disp = '<h3>' + data['regular-title'] + '</h3>' + '<br>' + \" \\r\\n\" + data['regular-body']\n",
    "                                    elif 'post_html' in data.keys():\n",
    "                                        disp = data['post_html']\n",
    "                                        JSON_type = \"SVC\"\n",
    "                                        date = data['date']\n",
    "                                    else:\n",
    "                                        print(f\"CANNOT PARSE: {name}\")\n",
    "                                        disp = \"\"\n",
    "                                        JSON_type = \"SVC\"\n",
    "                                        date = data['date']\n",
    "                                    return disp, JSON_type, date\n",
    "\n",
    "                                disp, JSON_type, date = json_structureizer(data)\n",
    "\n",
    "                                def post_titler(data):\n",
    "                                    if 'slug' in data.keys():\n",
    "                                        post_title = data['slug']\n",
    "                                    else:\n",
    "                                        post_title = name\n",
    "                                    \n",
    "                                    return post_title\n",
    "                                \n",
    "                                post_title = post_titler(data)\n",
    "\n",
    "                                html_base = \"<!DOCTYPE html>\" + \"\\r\\n\" + '<html lang=\"en\">' + \"\\r\\n\" + '<meta charset=\"utf-8\">' + '\\r\\n <head>' + f\"<title>{post_title}</title>\" + '\\r\\n' + '<link rel=\"stylesheet\" type=\"text/css\" href=\"nav.css\"/> </head>' + \"\\r\\n  <body><h6>\"\n",
    "\n",
    "                                def html_establisher(data, date, disp, Tags, from_blog, op, post_type, idnum):\n",
    "                                    if post_type == 'answer':\n",
    "                                        if 'asking_name' in data.keys() and data['asking_name'] != []:\n",
    "                                            asker = data['asking_name']\n",
    "                                        else:\n",
    "                                            asker = 'Anon'\n",
    "                                        disp = f\"<blockquote><i>{asker} asked: \\r\\n\\r\\n <blockquote>{data['question']}</i></blockquote></blockquote>\" + \"\\r\\n\\r\\n\" + \" \\r\\n \\r\\n <hr>\" + data['answer']\n",
    "                                        html_out = html_base +  date + \" \\r\\n\" + disp\n",
    "                                    elif post_type == 'text' or post_type == 'regular':\n",
    "                                        html_out = html_base +  date + \" \\r\\n <p>\" + disp + \"</p>\"\n",
    "                                    elif post_type == 'photo': \n",
    "                                        cap = \"\"\n",
    "                                        if 'photoset_photos' in data.keys() and data['photoset_photos'] != []:\n",
    "                                            b = []\n",
    "                                            index_num = 0\n",
    "                                            while index_num < len(data['photoset_photos']):\n",
    "                                                Width = data['photoset_photos'][index_num]['width']\n",
    "                                                Height = data['photoset_photos'][index_num]['height']\n",
    "                                                hq = data['photoset_photos'][index_num]['high_res']\n",
    "                                                b.append(f'<div class=\"indiv_pics\"> <img width={Width}px height={Height}px src={hq}> </div>')\n",
    "                                                index_num += 1\n",
    "                                            disp = ' <br/>\\r\\n '.join(b)\n",
    "                                        else:\n",
    "                                            if 'photos' in data.keys() and data['photos'] != []:\n",
    "                                                pics = data['photos']\n",
    "                                                disp = []\n",
    "                                                for dictionary in pics:\n",
    "                                                    disp.append(f\"<img src={dictionary['photo-url-1280']}>\")\n",
    "                                                disp = \" \\r\\n\".join(disp)\n",
    "                                            elif \"photo-url-1280\" in data.keys() and data['photo-url-1280'] != \"\":\n",
    "                                                disp = '<img src=\"' + data['photo-url-1280'] + '\"/>'\n",
    "\n",
    "                                        if 'photo-caption' in data.keys() and data['photo-caption'] != []:\n",
    "                                            cap = data['photo-caption']\n",
    "                                        elif 'caption' in data.keys() and data['caption'] != []:\n",
    "                                            cap = data['caption'] \n",
    "                                            \n",
    "                                        if \"photo-url-1280\" not in data.keys() and 'photoset_photos' not in data.keys() and 'post_html' in data.keys() and data['post_html'] != []:\n",
    "                                            disp = data['post_html']  \n",
    "                                            cap = ''\n",
    "                                        elif cap == \"\": \n",
    "                                            cap = ''\n",
    "\n",
    "                                        html_out = html_base + date + \" \\r\\n <p>\" + disp + \"</p>\" + cap\n",
    "                                    elif post_type == 'audio':\n",
    "                                        if 'id3-title' in data.keys() and data['id3-title'] != '':\n",
    "                                            disp = f\"{data['audio-embed']}\" + \" \\r\\n\" + f\"{data['id3-title']} by {data['id3-artist']}, on album {data['id3-album']}. \\r\\n \\r\\n {data['audio-caption']}\"\n",
    "                                        elif 'post_html' in data.keys():\n",
    "                                            disp = f\"{data['embed']}\" + \" \\r\\n\" + f\"{data['post_html']}\" \n",
    "                                        elif 'audio-embed' in data.keys():\n",
    "                                            disp = f\"{data['audio-embed']}\" + \" \\r\\n\" + f\"{data['audio-caption']}\"\n",
    "                                        else:\n",
    "                                            print(f\"AUDIO ERRROR: {name}\")\n",
    "                                        \n",
    "                                        html_out = html_base + date + \" \\r\\n <p>\" + disp + \"</p>\"\n",
    "                                    elif post_type == 'video':\n",
    "                                        if 'video-source' in data.keys() and data['video-source'] != '':\n",
    "                                            disp = f\"Original video url:\\r\\n{data['video-source']} \\r\\n \\r\\n {data['video-caption']}\"\n",
    "                                        elif 'post_html' in data.keys() and data['post_html'] != '':\n",
    "                                            disp = f\"{data['post_html']}\"\n",
    "                                        else:\n",
    "                                            print(f\"VIDEO ERROR: {name}\")\n",
    "\n",
    "                                        html_out = html_base + date + \" \\r\\n <p>\" + disp\n",
    "                                    elif post_type == 'link':\n",
    "                                        if 'link-url' in data.keys() and data['link-url'] != '':\n",
    "                                            if 'link-text' in data.keys():\n",
    "                                                disp = f\"{data['link-text']}\\r\\n at {data['link-url']}\\r\\n \\r\\n {data['link-description']}\"\n",
    "                                            else:\n",
    "                                                disp = f\"{data['link-url']}\\r\\n \\r\\n {data['link-description']}\"\n",
    "                                        \n",
    "                                        html_out = html_base + date + \" \\r\\n <p>\" + disp + \"</p>\"\n",
    "                                    elif post_type == 'chat':\n",
    "                                        if 'conversation-title' in data.keys():\n",
    "                                            disp = f\"<b>{data['conversation-title']}</b> \\r\\n \\r\\n {data['conversation-text']}\"\n",
    "                                        elif 'post_html' in data.keys():\n",
    "                                            disp = f\"{data['post_html']}\"\n",
    "                                        else:\n",
    "                                            print(f\"CHAT ERROR: {name}\")\n",
    "\n",
    "                                        html_out = html_base + date + \" \\r\\n <p>\" + disp + \"</p>\"\n",
    "                                    elif post_type == 'conversation':\n",
    "                                        if 'conversation-title' in data.keys():\n",
    "                                            disp = f\"<b>{data['conversation-title']}</b> \\r\\n \\r\\n {data['conversation-text']}\"\n",
    "                                        elif 'conversation' in data.keys():\n",
    "                                            c = []\n",
    "                                            cindex_num = 0\n",
    "                                            while cindex_num < len(data['conversation']):\n",
    "                                                label = data['conversation'][cindex_num]['label']\n",
    "                                                phrase = data['conversation'][cindex_num]['phrase']\n",
    "                                                c.append(f'<p><b>{label}</b> {phrase}</p> <br/> ')\n",
    "                                                cindex_num += 1\n",
    "                                            disp = ' \\r\\n '.join(c)\n",
    "                                        else: \n",
    "                                            print(f\"CONVERSATION ERROR: {name}\")\n",
    "                                        \n",
    "                                        html_out = html_base + date + \" \\r\\n <p>\" + disp + \"</p>\"\n",
    "                                    elif post_type == 'quote':\n",
    "                                        if 'quote-source' in data.keys():\n",
    "                                            disp = f\"{data['quote-source']}     {data['quote-text']}\"\n",
    "                                        else:\n",
    "                                            print(f\"QUOTE ERROR: {name}\")\n",
    "\n",
    "                                        html_out = html_base + date + \" \\r\\n <p>\" + disp + \"</p>\"\n",
    "                                    else:\n",
    "                                        print(f\"NO VALID POST TYPE: {name}\")\n",
    "                                        html_out = f\"ERROR, SEE JSON {name}\"\n",
    "                                    \n",
    "                                    return html_out\n",
    "                    \n",
    "                                html_out = html_establisher(data, date, disp, Tags, from_blog, op, post_type, idnum)\n",
    "                                html_out = html_out + \" \\r\\n <p>\" + f\"<sub>Tagged: \\r\\n <blockquote>{Tags}</blockquote></sub>\" + f'<footer style=\"text-align:right\"><sub>via {from_blog}. Originally posted by {op}, re/posted on {date}. {post_type} post. {idnum}</sub></footer>' + \"</body>\"\n",
    "                                \n",
    "                                def stuff_remover(html_out):\n",
    "\n",
    "                                    ## STEP 3.2: Determine whether or not post contains a readmore.\n",
    "                                    if \"Keep reading\" in html_out:\n",
    "                                        print(f\"READMORE: {name} contains a readmore.\")\n",
    "\n",
    "                                    if 'reblog-avatar' in html_out:\n",
    "                                        html_out = re.sub('<a class=\"reblog-avatar.*?}\" >', ' ', html_out)\n",
    "                                        html_out = re.sub('<img class=\"reblog-avatar-image-thumb\".*?\" >', ' ', html_out)\n",
    "\n",
    "                                    if 'https://www.youtube.com/' in html_out:\n",
    "                                        html_out = re.sub('<figure.*?https://www.youtube.com/.*?/figure>', '[INSERT YOUTUBE VIDEO HERE]', html_out)\n",
    "                                        html_out = re.sub('<figure class=\"tmblr-full tmblr-embed\" data-provider=\"youtube.*?</figure>\"','[INSERT YOUTUBE VIDEO HERE]',html_out)\n",
    "                                    \n",
    "                                    return html_out\n",
    "\n",
    "                                html_out = stuff_remover(html_out)\n",
    "                                \n",
    "                                if search_term in html_out:\n",
    "\n",
    "                                    def the_identify_spell(parsed_ids, dup_index, index):\n",
    "                                        if idnum in parsed_ids:\n",
    "                                            dup_index += 1\n",
    "                                        else: \n",
    "                                            index += 1\n",
    "                                            parsed_ids.append(idnum)\n",
    "                                        return parsed_ids, dup_index, index\n",
    "                                \n",
    "                                    parsed_ids, dup_index, index = the_identify_spell(parsed_ids, dup_index, index)\n",
    "\n",
    "                                    if 'CANNOT CURRENTLY DISPLAY' in html_out:\n",
    "                                        print(f\"COULD NOT WRITE: {name}\")\n",
    "                                    else:\n",
    "                                        def html_writer(htmlpath, date, idnum, op, post_title):\n",
    "                                            ## STEP 3.4: Name the html file. \n",
    "                                            htmlname = f\"{htmlpath}\\\\{date[:10]}-{date[11:13]}-{date[14:16]}-{date[17:19]}_{idnum}-{op}_{post_title}.html\"\n",
    "\n",
    "                                            ## STEP 5.0: Write to html.\n",
    "                                            html_file = open(htmlname, \"w\", encoding=\"utf8\")\n",
    "                                            html_file.write(html_out)\n",
    "                                            html_file.close()\n",
    "\n",
    "                                        html_writer(htmlpath, date, idnum, op, post_title)\n",
    "        os.startfile(htmlpath)\n",
    "        print(f\"- {index} unique files processed. \\n- {len(fnmatch.filter(os.listdir(jsonpath), '*.json'))} json files in the folder. \\n- {dup_index} duplicates found.\")\n",
    "\n",
    "root = tk.Tk()\n",
    "root.title(\"JSON to HTML\")\n",
    "myapp = App(root)\n",
    "\n",
    "myapp.mainloop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd97ce7",
   "metadata": {},
   "source": [
    "## EBOOK MAKER (FROM HTMLS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e90849",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-03-23-08-53-51_679504124785672192-lilacstarvix_meeting-people-a-sidestory\n",
      "2022-04-05-16-54-31_680712126597349376-nartothelar_i-was-so-afraid-of-admitting-i-shipped-emmet-and\n",
      "2022-04-13-21-26-35_681454018900492288-jinbugs_havent-we-met-before-oh-sorry-i-mistook-you\n",
      "2022-04-19-15-59-54_681977047766155264-fluorescent-air-fresheners_together-were-a-trainwreck-these-motherfuckers\n",
      "2022-04-19-23-48-01_682006498378973184-jinbugs_come-here-i-can-make-you-so-so-so-much-worse\n",
      "2022-05-06-06-03-38_683479681985642496-esprei_showdown\n",
      "2022-05-10-14-01-29_683872133080924160-tomorobo-illust_see-hi-res-version\n",
      "2022-05-12-08-03-01_684030774436085760-seagiri_designs-from-my-au-still-got-no-name-for-it\n",
      "2022-05-12-09-34-50_684036551083163648-seagiri_el-huevo\n",
      "2022-05-12-20-50-31_684079061719465984-cloudcreates_cloudcreates-emmet-internal-dialogue-murder\n",
      "2022-05-13-09-37-13_684127298645016576-seagiri_unfinishedsketches\n",
      "2022-05-15-04-36-48_684289591387324416-seagiri_love-is-in-the-air\n",
      "2022-05-18-04-29-23_684560915526533121-seagiri_are-they-angry-or-are-they-just-really-into-it\n",
      "2022-05-20-05-59-43_684747792924688384-texeoghea_texeoghea-this-was-gonna-have-more-panels-but-i\n",
      "2022-05-23-05-10-21_685016478251106304-esprei_emmet-makes-a-peace-offering-to-volo\n",
      "2022-05-26-01-26-42_685274198489382912-seagiri_chatter\n",
      "2022-06-12-02-25-38_686818054883180544-seagiri_twitter-pals-asked-for-softer-trainwreckshipping\n",
      "2022-06-12-22-53-55_686895331655417856-esprei_good-question-volo-i-ask-myself-the-same-thing\n",
      "2022-06-20-02-46-54_687544168104558592-seagiri_\n",
      "2022-06-28-00-50-50_688261641211641856-esprei_surprise-him\n",
      "2022-07-10-20-09-28_689421700083990528-nartothelar_them\n",
      "2022-07-20-07-35-48_690280252593864704-seagiri_wingmen\n",
      "2022-07-22-01-37-30_690438904711692288-seagiri_the-trainwreck-ever\n",
      "2022-07-23-02-28-59_690532740969496576-seagiri_trainwreck\n",
      "2022-07-26-16-29-56_690857439310053377-nartothelar_smooches\n",
      "2022-07-26-23-36-46_690884293680054272-seagiri_comfort-i-cant-draw-poses\n",
      "2022-07-29-07-00-37_691093412489887744-seagiri_little-pistol\n",
      "2022-08-02-03-22-12_691442058710401024-nartothelar_competitive-emmet-is-better-at-racing-usually\n",
      "2022-08-02-04-23-52_691445938164793344-seagiri_volo-doodles-from-my-au\n",
      "2022-08-09-18-40-18_692133999010775040-esprei_bonus-shoutout-to-lumartical-for-this\n",
      "2022-08-15-04-55-19_692625677797687296-seagiri_tangled-mess\n",
      "2022-08-20-01-20-00_693065116046032896-arrowsperpetualcringe_these-two\n",
      "2022-08-22-23-15-45_693329089285734400-seagiri_hiya-just-wanted-to-say-that-i-absolutely-adore\n",
      "2022-08-23-12-04-14_693377438415241217-arrowsperpetualcringe_oh-god-oh-fuck-what-did-you-say-to-them\n",
      "2022-08-25-06-23-31_693537195799216128-arrowsperpetualcringe_trainwreckshipping-except-with-lyrics-from-streets\n",
      "2022-08-25-07-49-36_693542611876757504-arrowsperpetualcringe_so-like-the-absolute-dumbass-i-am-i-mightve-come\n",
      "2022-08-31-05-33-12_694077612024381440-arrowsperpetualcringe_hello-tell-me-anything-about-your-volo-au\n",
      "2022-09-01-04-56-18_694165887502188544-esprei_trainwreckshipping-art-dump-more-below\n",
      "2022-09-02-07-15-31_694265243402174464-arrowsperpetualcringe_sir-i-love-your-trainwreckshipping-stuff-it\n",
      "2022-09-02-17-40-15_694304548640129024-arrowsperpetualcringe_hello-tell-me-anything-about-your-volo-au\n",
      "2022-09-03-12-39-32_694376226299723776-arrowsperpetualcringe_time-leap-back-to-the-station-context-time-leap\n",
      "2022-09-04-23-00-18_694505878195470336-esprei_baby-safety-is-verrrrrrry-important\n",
      "2022-09-06-11-55-42_694645259317182464-arrowsperpetualcringe_morning-routine\n",
      "2022-09-06-12-13-41_694646390256697344-kurixta_kurixta-togekiss-volo-kinda-pretty-tho\n",
      "2022-09-09-00-47-19_694874998678208512-baloneydoggo_\n",
      "2022-09-09-00-48-37_694875080265809920-shoeqorn_\n",
      "2022-09-09-10-50-24_694912941813907456-arrowsperpetualcringe_time-leap-au-idea-i-cant-imagine-emmet-would-be\n",
      "2022-09-09-12-50-38_694920505723174912-arrowsperpetualcringe_more-time-leap-au-doodles-probably-wont-be-canon\n",
      "2022-09-15-07-05-14_695442356939489280-arrowsperpetualcringe_haha-i-just-had-a-fucked-up-idea-submas-twins\n",
      "2022-09-16-00-41-20_695508801554710528-seagiri_sin-ti\n",
      "2022-09-16-04-42-59_695524004714381312-seagiri_i-appreciate-u-and-ur-contributions-for-trainwreck\n",
      "2022-09-16-05-06-30_695525484153405440-esprei_esprei-trainwreckshipping-art-dump-more\n",
      "2022-09-16-18-38-31_695576571977875456-seagiri_how-do-you-think-emmet-would-react-to-finding-out\n",
      "2022-09-23-15-02-00_696197128836513792-septiseph_septiseph-imagining-how-hilarious-it-would-be\n",
      "2022-09-27-13-58-32_696555523281158144-arrowsperpetualcringe_concept-trainwreckshipping-except-volo-gets-eebie\n",
      "2022-09-28-13-21-39_696643799637786624-kurixta_yeeeeeeeeeeeeeeeeeeesssss-my-boys\n",
      "2022-10-01-04-04-30_696880537920487424-ghostpengu_\n",
      "2022-10-04-16-19-22_697198562591801344-waywardstation_oi-im-gonna-grow-a-pair-and-finally-ask-this-i\n",
      "2022-10-15-22-17-03_698217632663486464-esprei_trainwreckshipping-art-dump-part-2-more-below\n",
      "2022-11-25-23-31-56_701936819942703104-esprei_please-make-way-for-subway-boss-volo\n",
      "2022-11-28-22-42-07_702205476305354752-arrowsperpetualcringe_thinking-about-trainwreckshipping-books-and\n",
      "2022-12-03-18-58-49_702644412085305345-sweetapplecurry_yall-draw-volo-too-nice-i-want-him-coming-out-of\n",
      "2022-12-30-02-08-57_705026994907283456-esprei_yeah-emmet-know-your-limits\n",
      "2023-01-01-06-53-49_705226111557271552-seagiri_happy-new-year\n",
      "2023-01-09-03-55-13_705939650852929536-raisans-art_i-did-not-get-distracted-nope-not-at-all-ok\n",
      "2023-01-10-16-22-48_706077281024688128-raisans-art_this-comic-is-gonna-need-3-parts-so-just-hold\n",
      "2023-01-11-18-21-56_706175373844594688-raisans-art_woah-part-2-of-soft-train-wreck-comic-prev\n",
      "2023-01-12-23-30-06_706285359036760064-zhampy-deactivated20230923_zhampy-pkmn-mellis-unwanted\n",
      "2023-01-12-23-50-45_706286657479065600-sweetapplecurry_i-havent-liked-how-ive-been-drawing-the-boys\n",
      "2023-01-13-08-36-38_706319743829803008-forthewoolfy_forthewoolfy-between-the-23rd-of-january-and\n",
      "2023-01-13-19-09-53_706359584204472320-raisans-art_last-part-of-soft-trainwrecks-prev-next-lmao-u\n",
      "2023-01-15-14-45-39_706524153573982208-raisans-art_volo-makes-it-down-the-subway-line-what-he-finds\n",
      "2023-01-16-00-58-12_706562692362665984-raisans-art_heres-a-gift-for-giving-me-brainrot-for\n",
      "2023-01-16-03-59-03_706574070626582528-raisans-art_i-love-seeing-how-flustered-volo-is-once-he-gets\n",
      "2023-01-17-17-25-00_706715373421150208-raisans-art_woah-no-way-more-soft-trainwreckshipping-prev\n",
      "2023-01-17-18-49-24_706720682903535616-esprei_emmet-are-you-going-to-answer-him\n",
      "2023-01-18-18-12-22_706808949919432704-raisans-art_haha-yall-fuckin-thought-short-part-cuz-i-had-to\n",
      "2023-01-19-04-10-06_706846556097216512-raisans-art_heyo-so-ive-been-enjoying-your\n",
      "2023-01-19-13-45-23_706882750185177088-raisans-art_\n",
      "2023-01-20-16-43-31_706984554008821761-raisans-art_ohhhh-gang-we-got-some-of-emmets-thoughts-on-the\n",
      "2023-01-21-13-04-26_707061367616733184-raisans-art_i-just-cant-help-but-wonder-what-would-happen-if\n",
      "2023-01-21-17-01-57_707076311056809984-raisans-art_ooooh-my-man-has-a-plan-prev-next-look-at\n",
      "2023-01-22-05-54-27_707124912544940032-raisans-art_if-ingo-is-making-it-back-in-this-scenario-i-love\n",
      "2023-01-22-17-06-19_707167182613889024-raisans-art_oh-theyre-battling-and-its-getting-serious\n",
      "2023-01-22-17-26-39_707168462026539008-raisans-art_now-youve-got-me-excited-to-see-this-mutual\n",
      "2023-01-22-21-29-35_707183745500954624-esprei_esprei-please-make-way-for-subway-boss-volo\n",
      "2023-01-23-16-28-21_707255390501584896-raisans-art_oh-there-it-is-prev-next-finally-someone\n",
      "2023-01-23-18-35-30_707263390651957248-raisans-art_volos-stupid-lil-flushed-face-a-collection-from\n",
      "2023-01-23-21-26-55_707274175664046080-mushroomsandteeth_\n",
      "2023-01-23-21-47-03_707275441630855168-esprei_trainwreckshipping-day-1-unova-nimbasa-city\n",
      "2023-01-24-14-38-38_707339085184909312-raisans-art_and-they-lived-fruity-ever-after-prev-next-well\n",
      "2023-01-24-18-04-28_707352035592388608-esprei_esprei-trainwreckshipping-day-1-unova-nimbasa\n",
      "2023-01-24-18-19-17_707352967783792640-forthewoolfy_forthewoolfy-day-1-of-trainwreckshipping-week-i\n",
      "2023-01-25-04-50-48_707392699231354880-nartothelar_trainwreckshipping-week-day-1-summer\n",
      "2023-01-25-15-23-48_707432524026085376-raisans-art_lunch-time-we-continue-forward-with-no\n",
      "2023-01-25-20-19-05_707451100923674624-sweetapplecurry_day-1-of-trainwreckshipping-week-summer-they-go\n",
      "2023-01-26-06-19-32_707488878179893248-umbreiion_trainwreckshipping-day-2-formal-aka-my-excuse\n",
      "2023-01-26-15-54-00_707525021058433024-raisans-art_ohhh-they-are-soooo-awkward-prev-next-same-you\n",
      "2023-01-26-17-06-36_707529588745666560-umbreiion_i-did-this-forever-ago-for-my-possessedvolo-au\n",
      "2023-01-27-17-09-50_707620388859002880-athousanddayyys_athousanddayyys-black-coffee\n",
      "2023-01-27-20-05-34_707631445061091328-forthewoolfy_forthewoolfy-day-5-gift-volo-giving-emmet-a-lil\n",
      "2023-01-28-02-02-31_707653901875396608-seagiri_seagiri-sin-ti\n",
      "2023-01-28-16-17-08_707707669725741056-umbreiion_fun-idea-does-volo-not-remember-what-he-does-when\n",
      "2023-01-29-23-03-46_707823850725998592-boeing-787_mhachina-older-trainwreckshipping-doodle-i-forgot\n",
      "2023-01-30-02-03-09_707835135830163456-forthewoolfy_forthewoolfy-day-4-fairy-tale-emmet-the\n",
      "2023-01-30-20-05-12_707903212487950336-forthewoolfy_forthewoolfy-day-2-for-trainwreckshipping-week\n",
      "2023-01-30-23-05-05_707914529774944256-boeing-787_mhachina-we-keeping-finding-items-of-togepi\n",
      "2023-01-31-17-07-29_707982628504125440-seagiri_seagiri-wingmen\n",
      "2023-02-18-05-31-36_709569593106219008-nartothelar_\n",
      "2023-03-05-03-19-19_710920224608780288-nartothelar_commission-for-deerprynce-emmet-comforting-volo\n",
      "2023-03-27-18-55-31_712972258445049856-raisans-art_gosh-remember-when-softwreck-was-a-thing-so-did-i\n",
      "2023-03-28-18-55-48_713062873416548352-raisans-art_were-moving-along-now-prev-next-emmet-is\n",
      "2023-03-29-16-26-38_713144085604663296-raisans-art_were-aaaaall-on-the-same-page-prev\n",
      "2023-04-03-21-57-27_713617883665727488-raisans-art_i-am-very-curious-may-i-ask-what-gave-you-the\n",
      "2023-04-05-03-38-48_713729956280188928-nartothelar_fluffy-trainwreck-doodles\n",
      "2023-04-05-23-07-45_713803500225708032-raisans-art_get-yourself-a-man-who-will-listen-to-you-info\n",
      "2023-04-06-15-08-22_713863937763983360-raisans-art_nice-save-buddy-prev-next-i-just-love-drawing\n",
      "2023-04-12-18-32-24_714420356059922432-sweetapplecurry_i-need-them-both-simultaneously-happy-okay\n",
      "2023-04-27-15-44-25_715768742284541952-raisans-art_second-date-pog-prev-next-volo-is-trying\n",
      "2023-04-30-03-13-05_715993262682406912-uas-art_au-where-volo-is-spit-out-in-unova-with-no\n",
      "2023-04-30-15-16-06_716038751458082816-raisans-art_woah-hey-that-happened-prev-next-emmet\n",
      "2023-05-17-15-56-46_717581458166956032-raisans-art_a-couple-silly-drawings-i-made-on-paper-translated\n",
      "2023-05-19-18-52-03_717773680408657921-nartothelar_honeymoon-un-deux-trois\n",
      "2023-05-26-03-03-28_718348178454446080-sweetapplecurry_instigators\n",
      "2023-05-30-19-45-00_718773577333243904-raisans-art_back-to-work-prev-next-its-been-a-hot-second\n",
      "2023-05-31-16-36-56_718852342708076544-raisans-art_realization-of-what-you-did-in-a-panic-prev\n",
      "2023-06-06-18-22-59_719402596853596160-raisans-art_ending-this-lil-arc-off-before-we-head-into-date\n",
      "2023-06-11-20-02-10_719861822034968576-esprei_esprei-please-make-way-for-subway-boss-volo\n",
      "2023-06-11-20-03-33_719861908318060544-esprei_esprei-trainwreckshipping-art-dump-part-2-more\n",
      "2023-06-11-20-04-27_719861965611220992-esprei_esprei-baby-safety-is-verrrrrrry-important\n",
      "2023-06-11-20-04-51_719861990553796608-esprei_esprei-trainwreckshipping-art-dump-more\n",
      "2023-06-11-20-05-20_719862020663623680-esprei_esprei-bonus-shoutout-to-lumartical-for-this\n",
      "2023-06-11-20-05-42_719862043995488256-esprei_esprei-surprise-him\n",
      "2023-06-11-20-06-00_719862062820589568-esprei_esprei-good-question-volo-i-ask-myself-the-same\n",
      "2023-06-11-20-06-39_719862103547265024-esprei_esprei-emmet-are-you-going-to-answer\n",
      "2023-06-16-21-54-55_720321899966726144-raisans-art_ingo-threats-volo-to-never-touch-his-brother-but\n",
      "2023-06-27-15-21-32_721293716586921984-esprei_im-excited-for-emmet-month-even-though-i-dont\n",
      "2023-07-10-05-14-23_722433279335251968-esprei_your-trainwreckshipping-is-so-cute-im-in-love\n",
      "2023-07-12-19-13-36_722667272109506560-nartothelar_from-afar-tfw-youre-an-npc-trying-to-get-in-the\n",
      "2023-07-15-11-26-31_722909676848726016-sweetapplecurry_day-13-of-emmet-month-favorite-ship-mcemmet\n",
      "2023-07-15-11-51-49_722911268248354816-sweetapplecurry_a-follow-up-thats-a-bit-spicy-lol\n",
      "2023-07-23-16-07-20_723652119699341312-raisans-art_catching-up-on-month-of-emmet-continues-w-day\n",
      "2023-08-09-21-55-44_725214187539791872-sweetapplecurry_pet-names-3\n",
      "2023-08-13-23-39-46_725583120235216896-nartothelar_commission-for-deerprynce-my-take-on-some\n",
      "2023-08-14-17-27-07_725650272537411584-nartothelar_so-that-one-au-where-emmet-reincarnates-constantly\n",
      "2023-08-14-18-36-18_725654624859783168-nartothelar_does-reincarnated-emmet-retain-his-past-lives\n",
      "2023-08-20-03-52-40_726142613482356736-nartothelar_another-reincarnationimmortal-au-comic-a-chance\n",
      "2023-11-12-05-21-18_733758335273271296-esprei_\n",
      "2023-11-12-14-53-01_733794304677560320-esprei_\n",
      "2023-12-06-18-07-04_735980840079753216-esprei_congrats-you-singlehandedly-got-me-and-my-friend\n",
      "2023-12-26-06-14-08_737747925568045056-sweetapplecurry_hope-everyone-has-a-good-holiday\n",
      "2024-01-01-15-42-45_738327281075879936-esprei_\n",
      "2024-01-01-17-22-42_738333569478508544-umbreiion_rockstar-volo-is-built-different-based-on-this\n",
      "2024-02-03-15-09-32_741314891143659520-esprei_two-tall-guys-based-on-this\n",
      "2024-02-15-00-52-23_742348128153419776-sweetapplecurry_trying-out-the-pokemanga-style\n",
      "2024-02-22-22-11-17_743062768049127424-esprei_i-just-recently-got-into-the-submas-fandom-and\n",
      "2024-02-26-23-49-02_743431305943007232-nartothelar_messenger-joltik\n",
      "2024-03-29-05-27-42_746261119178620928-sweetapplecurry_i-cant-wait-to-abuse-photo-mode-check-reblogs\n",
      "2024-04-15-03-19-51_747793223324483584-sweetapplecurry_i-worked-on-this-for-a-week-and-im-my\n",
      "2024-06-15-15-08-44_753364237703905280-sweetapplecurry_ref-undercut\n",
      "2024-06-15-18-53-42_753378391061938176-sweetapplecurry_ex-knows-best-ref-undercut\n",
      "2024-06-30-17-43-24_754732922708312065-purple-boi-clefairy-god_\n",
      "2024-09-23-17-56-00_762434458259521536-esprei_3-i-drew-the-sleepy-trainwreck-everyone-elses\n",
      "2024-11-22-04-58-21_767821350750584832-nartothelar_commission-for-hybridnova-ingo-and-elesa\n",
      "2024-12-07-18-01-52_769229599326470144-arrowsperpetualcringe_im-drawing-some-submas-and-i-wonder-if\n",
      "2025-02-13-23-02-53_775409131514413056-nartothelar_ichoochooseyouweek-day-4-date-when-emmet\n",
      "2025-02-14-18-42-32_775483349193146368-sweetapplecurry_happy-valentines-day-yall\n",
      "2025-04-08-02-05-05_780222233829376000-arrowsperpetualcringe_i-want-to-finish-mirror-image-because-its-a\n",
      "2025-05-02-17-53-38_782456238296416256-sweetapplecurry_dont-harass-the-depot-agents\n",
      "2025-09-11-21-56-09_794430295701094400-raliciel_\n",
      "2025-09-12-18-35-21_794508259445932032-esprei_trainwreckshipping-visual-novel-its-verrry\n",
      "2025-09-22-02-20-44_795352911655878656-sweetapplecurry_my-emmet-in-the-pokemas-photo-editor-and-then\n",
      "2025-10-03-21-52-43_796423213579190272-tokomplee_\n",
      "2025-10-11-17-42-06_797132221515464704-esprei_a-short-intro-comic-of-sorts-for-my-futureemmet\n",
      "2025-10-14-16-36-09_797399863282253824-nartothelar_it-seems-like-emmet-is-just-attracted-to-fake\n",
      "epub written successfully! Check it out!\n"
     ]
    }
   ],
   "source": [
    "from ebooklib import epub\n",
    "from bs4 import BeautifulSoup\n",
    "import html\n",
    "import re\n",
    "import pathlib\n",
    "import os\n",
    "import os.path\n",
    "\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "from tkinter import ttk\n",
    "\n",
    "\n",
    "class App(tk.Frame):\n",
    "    def __init__(self, master): # Runs as soon as program starts\n",
    "        super().__init__(master)\n",
    "        \n",
    "        frm = ttk.Frame(root, padding='0.1i')\n",
    "        frm.grid()\n",
    "        frm.rowconfigure(1, weight=3, minsize='0.5i')\n",
    "        frm.rowconfigure(2, weight=3, minsize='0.5i')\n",
    "        frm.columnconfigure(0, weight=3, minsize='0.5i')\n",
    "        \n",
    "        ttk.Button(\n",
    "            frm, text=\"Where are your HTML files?\", command=self.choose_directory).grid(column=0, row=0, columnspan=3, sticky=\"NW\")\n",
    "        self.path_display_text = tk.StringVar()\n",
    "        self.path_display_text.set(\"Selected Directory: \")\n",
    "        self.htmlpath = \"\"\n",
    "        self.directory_label = ttk.Label(frm, text=\"Selected Directory: \", width=80)\n",
    "        self.directory_label.grid(column=0, row=1, columnspan=3)\n",
    "        self.directory_label['textvariable'] = self.path_display_text\n",
    "        \n",
    "        self.status_display_text = tk.StringVar()\n",
    "        self.status_label = ttk.Label(frm, text=\"\", width=80)\n",
    "        self.status_label.grid(column=0, row=2, columnspan=3)\n",
    "        self.status_label['textvariable'] = self.status_display_text\n",
    "        \n",
    "        self.confirm_button = ttk.Button(frm, text=\"Confirm\", command=self.execute) # Self passes itself as first param\n",
    "        self.confirm_button.grid(column=1, row=3, columnspan=1, sticky=\"SE\")\n",
    "        self.confirm_button.state(['disabled'])\n",
    "        self.exit_button = ttk.Button(frm, text=\"Exit\", command=root.destroy)\n",
    "        self.exit_button.grid(column=2, row=3, columnspan=1, sticky=\"SE\")\n",
    "        \n",
    "        \n",
    "    def choose_directory(self):\n",
    "        htmlpath = filedialog.askdirectory(title=\"Where are your HTML files?\")\n",
    "        self.htmlpath = htmlpath\n",
    "        self.path_display_text.set(f\"Selected Directory: {htmlpath}\") # Sets text of label to htmlpath)\n",
    "        if os.path.exists(htmlpath): # If path exists, enable button\n",
    "            self.confirm_button.state(['!disabled'])\n",
    "\n",
    "    def execute(self):\n",
    "        \n",
    "        htmlpath = self.htmlpath\n",
    "        chapters = {}\n",
    "        chapter_links = []\n",
    "        imgs = []\n",
    "        index = 0\n",
    "\n",
    "        book = epub.EpubBook()\n",
    "        book.add_item(epub.EpubNav(uid = 'nav', file_name = 'nav.xhtml'))\n",
    "        book.spine = ['nav']\n",
    "        style = '''\n",
    "            @namespace epub \"http://www.idpf.org/2007/ops\";\n",
    "            body {\n",
    "                font-family: OpenDyslexic;\n",
    "            }\n",
    "            h6 {\n",
    "                text-align: left;\n",
    "                font-size: 10pt;\n",
    "                font-weight: 200;     \n",
    "            }\n",
    "            ol {\n",
    "                    list-style-type: none;\n",
    "            }\n",
    "            ol > li:first-child {\n",
    "                    margin-top: 0.3em;\n",
    "            }\n",
    "            nav[epub|type~='toc'] > ol > li > ol  {\n",
    "                list-style-type:square;\n",
    "            }\n",
    "            nav[epub|type~='toc'] > ol > li > ol > li {\n",
    "                    margin-top: 0.3em;\n",
    "            }\n",
    "            indiv_pics {\n",
    "                text-align: center;\n",
    "                page-break-inside: avoid;\n",
    "                object-align: center;\n",
    "            }\n",
    "            img {\n",
    "                max-width: 100%;\n",
    "                object-fit: contain;\n",
    "                width: auto;\n",
    "                object-align: center;\n",
    "            }\n",
    "            \n",
    "            blockquote {\n",
    "                font-size: 12pt;    \n",
    "            }\n",
    "            '''\n",
    "        nav_css = epub.EpubItem(\n",
    "            uid=\"style_nav\",\n",
    "            file_name=\"style/nav.css\",\n",
    "            media_type=\"text/css\",\n",
    "            content=style,\n",
    "            manifest=True,\n",
    "        )\n",
    "        book.add_item(nav_css)\n",
    "\n",
    "        intit = os.path.basename(os.path.normpath(htmlpath))\n",
    "        book.set_title(intit)\n",
    "        book.set_language(\"en\")\n",
    "\n",
    "        for file in os.listdir(htmlpath):\n",
    "            if file.endswith('.html'):\n",
    "                fname = os.path.join(htmlpath,file)\n",
    "                with open(fname, 'r', encoding=\"utf8\") as f:\n",
    "                    index = index + 1\n",
    "                    soup = BeautifulSoup(f.read(),'html.parser')\n",
    "                    # print(soup)\n",
    "                    title = file\n",
    "                    title = title.replace('.html','')\n",
    "                    print(title)\n",
    "                    # title = re.search('(?<=<h6>).*?(?=GMT)', str(soup))\n",
    "                    # title = title.group(0)\n",
    "                    filename = fname.replace(f\"{htmlpath}\\\\\", \"\")\n",
    "                    \n",
    "                    chapter = epub.EpubHtml(title = title, file_name = filename, media_type = 'application/xhtml+xml', content = str(soup), uid = str(index))\n",
    "                    chapter.add_item(nav_css)\n",
    "                    book.add_item(chapter)\n",
    "                    book.spine.append(chapter)\n",
    "                    chapter_links.append(epub.Link(href = filename, title = title, uid = str(index)))\n",
    "\n",
    "        book.toc = tuple(chapter_links)  \n",
    "        book.add_item(epub.EpubNcx(uid='ncx', file_name = 'toc.ncx'))\n",
    "        book.spine.append('ncx')\n",
    "\n",
    "        epub.write_epub(f\"{htmlpath}\\\\{intit}.epub\", book)\n",
    "        print(\"epub written successfully! Check it out!\")\n",
    "\n",
    "root = tk.Tk()\n",
    "root.title(\"JSON to HTML\")\n",
    "myapp = App(root)\n",
    "\n",
    "myapp.mainloop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
